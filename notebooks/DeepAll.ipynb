{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from importlib import reload\n",
    "import IPython\n",
    "mpl.rcParams['lines.linewidth'] = 0.25\n",
    "mpl.rcParams['axes.spines.top'] = False\n",
    "mpl.rcParams['axes.spines.right'] = False\n",
    "mpl.rcParams['axes.linewidth'] = 0.25\n",
    "\n",
    "import torch, argparse, os, shutil, inspect, json, numpy, math\n",
    "import netdissect\n",
    "from netdissect.easydict import EasyDict\n",
    "from netdissect import pbar, nethook, renormalize, parallelfolder, pidfile\n",
    "from netdissect import upsample, tally, imgviz, imgsave, bargraph, show\n",
    "from experiment import dissect_experiment\n",
    "\n",
    "torch.cuda.set_device(5)\n",
    "\n",
    "model_name='DA-SS-sketch'\n",
    "# choices are alexnet, vgg16, or resnet152.\n",
    "args = EasyDict(model=model_name, dataset='pacs-s', seg='netpqc', layer='layer3', quantile=0.01)\n",
    "resdir = 'results/%s-%s-%s-%s-%s' % (args.model, args.dataset, args.seg, args.layer, int(args.quantile * 1000))\n",
    "print(resdir)\n",
    "def resfile(f):\n",
    "    return os.path.join(resdir, f)\n",
    "\n",
    "print('### Load dataset!')\n",
    "dataset = dissect_experiment.load_dataset(args)\n",
    "sample_size = len(dataset)\n",
    "\n",
    "print(len(dataset))\n",
    "\n",
    "# Classifier labels\n",
    "from urllib.request import urlopen\n",
    "from netdissect import renormalize\n",
    "\n",
    "classlabels = dataset.classes\n",
    "print(classlabels)\n",
    "renorm = renormalize.renormalizer(dataset, target='zc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('### Load model!')\n",
    "model = torch.load('./'+model_name+'-torch16-0.pkl',map_location='cpu')\n",
    "model = model.cuda()\n",
    "\n",
    "indices = [0]\n",
    "batch = torch.cat([dataset[i][0][None,...] for i in indices])\n",
    "activations, res = model(batch.cuda())\n",
    "\n",
    "layername = args.layer\n",
    "upfn = dissect_experiment.make_upfn_without_hooks(args, dataset, layername, activations)\n",
    "percent_level = 1.0 - args.quantile\n",
    "\n",
    "print('### Collect quantile statistics!')\n",
    "pbar.descnext('rq')\n",
    "def compute_samples(batch, *args):\n",
    "    image_batch = batch.cuda()\n",
    "    activations, _ = model(image_batch)\n",
    "    acts = activations[layername].detach()\n",
    "    hacts = upfn(acts)\n",
    "    return hacts.permute(0, 2, 3, 1).contiguous().view(-1, acts.shape[1])\n",
    "rq = tally.tally_quantile(compute_samples, dataset,\n",
    "                          sample_size=sample_size,\n",
    "                          r=8192,\n",
    "                          num_workers=100,\n",
    "                          pin_memory=True,\n",
    "                          cachefile=resfile('rq.npz'))\n",
    "\n",
    "print('### Collect TopK!')\n",
    "pbar.descnext('topk')\n",
    "def compute_image_max(batch, *args):\n",
    "    image_batch = batch.cuda()\n",
    "    activations, _ = model(image_batch)\n",
    "    acts = activations[layername].detach()\n",
    "    acts = acts.view(acts.shape[0], acts.shape[1], -1)\n",
    "    acts = acts.max(2)[0]\n",
    "    return acts\n",
    "\n",
    "#topk => (64X100, 64X100)\n",
    "topk = tally.tally_topk(compute_image_max, dataset, sample_size=sample_size,\n",
    "        batch_size=50, num_workers=30, pin_memory=True,\n",
    "        cachefile=resfile('topk.npz'))\n",
    "\n",
    "def scale(intermediate_layer_output, rmax=1, rmin=0):\n",
    "    X_std = (intermediate_layer_output - intermediate_layer_output.min()) / (\n",
    "        intermediate_layer_output.max() - intermediate_layer_output.min())\n",
    "    X_scaled = X_std * (rmax - rmin) + rmin\n",
    "    return X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single image visualization\n",
    "rank=98\n",
    "percent_level=0.99\n",
    "\n",
    "unit_number = 170\n",
    "real_classlabels =['dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person']\n",
    "# print(topk.result()[0][unit_number][rank].item())\n",
    "# print('Before Image No.: ' + str(topk.result()[1][unit_number][rank].item()))\n",
    "image_number = topk.result()[1][unit_number][rank].item()\n",
    "image_number=3862\n",
    "print('Af ter Image No.: ' + str(image_number))\n",
    "# print(dataset.images[topk.result()[1][unit_number][rank]])\n",
    "\n",
    "iv = imgviz.ImageVisualizer((224, 224), source=dataset, quantiles=rq,\n",
    "        level=rq.quantiles(percent_level))\n",
    "batch = torch.cat([dataset[i][0][None,...] for i in [image_number]])\n",
    "truth = [classlabels[dataset[i][1]] for i in [image_number]]\n",
    "\n",
    "activations, output = model(batch.cuda())\n",
    "\n",
    "preds = output.max(1)[1]\n",
    "acts = activations[layername].detach()\n",
    "print(acts[0][unit_number].sum())\n",
    "\n",
    "imgs = [renormalize.as_image(t, source=dataset) for t in batch]\n",
    "prednames = [real_classlabels[p.item()] for p in preds]\n",
    "print( 'pred: ' + prednames[0], 'true: ' + truth[0])\n",
    "\n",
    "ivsmall = imgviz.ImageVisualizer((300, 300), source=dataset)\n",
    "mask_img = ivsmall.masked_image(batch[0], acts, (0, unit_number), percent_level=percent_level)\n",
    "display(show.blocks(\n",
    "    [[[mask_img],\n",
    "      [ivsmall.heatmap(acts.cpu(), (0, u), mode='nearest')]] for u in [unit_number]]\n",
    "))\n",
    "\n",
    "img_name = '%s-%s-%s-p%s-i%s-u%s.jpg' % (\n",
    "    args.model, args.dataset, args.layer, \n",
    "    int(percent_level * 1000), image_number, unit_number\n",
    ")\n",
    "print(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_img.save(img_name, quality=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tally)\n",
    "pbar.descnext('unit_images')\n",
    "\n",
    "iv = imgviz.ImageVisualizer((100, 100), source=dataset, quantiles=rq,\n",
    "        level=rq.quantiles(percent_level))\n",
    "def compute_acts(*image_batch):\n",
    "    image_batch = image_batch[0].cuda()\n",
    "    activations, _ = model(image_batch)\n",
    "    acts_batch = activations[layername]\n",
    "    return acts_batch\n",
    "\n",
    "k='90,10'\n",
    "unit_images = iv.masked_images_for_topk(\n",
    "        compute_acts, dataset, topk, k=k, num_workers=30, pin_memory=True,\n",
    "        cachefile=resfile('top'+k+'images.npz'))\n",
    "for u in [170]:\n",
    "    display(unit_images[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}